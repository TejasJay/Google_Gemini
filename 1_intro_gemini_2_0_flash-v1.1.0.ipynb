{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sqi5B7V_Rjim"
   },
   "outputs": [],
   "source": [
    "# Copyright 2024 Google LLC\n",
    "#\n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "#     https://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VyPmicX9RlZX"
   },
   "source": [
    "# Intro to Gemini 2.0 Flash\n",
    "\n",
    "\n",
    "<table align=\"left\">\n",
    "  <td style=\"text-align: center\">\n",
    "    <a href=\"https://colab.research.google.com/github/GoogleCloudPlatform/generative-ai/blob/main/gemini/getting-started/intro_gemini_2_0_flash.ipynb\">\n",
    "      <img width=\"32px\" src=\"https://www.gstatic.com/pantheon/images/bigquery/welcome_page/colab-logo.svg\" alt=\"Google Colaboratory logo\"><br> Open in Colab\n",
    "    </a>\n",
    "  </td>\n",
    "  <td style=\"text-align: center\">\n",
    "    <a href=\"https://console.cloud.google.com/vertex-ai/colab/import/https:%2F%2Fraw.githubusercontent.com%2FGoogleCloudPlatform%2Fgenerative-ai%2Fmain%2Fgemini%2Fgetting-started%2Fintro_gemini_2_0_flash.ipynb\">\n",
    "      <img width=\"32px\" src=\"https://lh3.googleusercontent.com/JmcxdQi-qOpctIvWKgPtrzZdJJK-J3sWE1RsfjZNwshCFgE_9fULcNpuXYTilIR2hjwN\" alt=\"Google Cloud Colab Enterprise logo\"><br> Open in Colab Enterprise\n",
    "    </a>\n",
    "  </td>\n",
    "  <td style=\"text-align: center\">\n",
    "    <a href=\"https://console.cloud.google.com/vertex-ai/workbench/deploy-notebook?download_url=https://raw.githubusercontent.com/GoogleCloudPlatform/generative-ai/main/gemini/getting-started/intro_gemini_2_0_flash.ipynb\">\n",
    "      <img src=\"https://www.gstatic.com/images/branding/gcpiconscolors/vertexai/v1/32px.svg\" alt=\"Vertex AI logo\"><br> Open in Vertex AI Workbench\n",
    "    </a>\n",
    "  </td>\n",
    "  <td style=\"text-align: center\">\n",
    "    <a href=\"https://github.com/GoogleCloudPlatform/generative-ai/blob/main/gemini/getting-started/intro_gemini_2_0_flash.ipynb\">\n",
    "      <img width=\"32px\" src=\"https://upload.wikimedia.org/wikipedia/commons/9/91/Octicons-mark-github.svg\" alt=\"GitHub logo\"><br> View on GitHub\n",
    "    </a>\n",
    "  </td>\n",
    "  <td style=\"text-align: center\">\n",
    "    <a href=\"https://goo.gle/40JXy6g\">\n",
    "      <img width=\"32px\" src=\"https://cdn.qwiklabs.com/assets/gcp_cloud-e3a77215f0b8bfa9b3f611c0d2208c7e8708ed31.svg\" alt=\"Google Cloud logo\"><br> Open in Cloud Skills Boost\n",
    "    </a>\n",
    "  </td>\n",
    "</table>\n",
    "\n",
    "<div style=\"clear: both;\"></div>\n",
    "\n",
    "<b>Share to:</b>\n",
    "\n",
    "<a href=\"https://www.linkedin.com/sharing/share-offsite/?url=https%3A//github.com/GoogleCloudPlatform/generative-ai/blob/main/gemini/getting-started/intro_gemini_2_0_flash.ipynb\" target=\"_blank\">\n",
    "  <img width=\"20px\" src=\"https://upload.wikimedia.org/wikipedia/commons/8/81/LinkedIn_icon.svg\" alt=\"LinkedIn logo\">\n",
    "</a>\n",
    "\n",
    "<a href=\"https://bsky.app/intent/compose?text=https%3A//github.com/GoogleCloudPlatform/generative-ai/blob/main/gemini/getting-started/intro_gemini_2_0_flash.ipynb\" target=\"_blank\">\n",
    "  <img width=\"20px\" src=\"https://upload.wikimedia.org/wikipedia/commons/7/7a/Bluesky_Logo.svg\" alt=\"Bluesky logo\">\n",
    "</a>\n",
    "\n",
    "<a href=\"https://twitter.com/intent/tweet?url=https%3A//github.com/GoogleCloudPlatform/generative-ai/blob/main/gemini/getting-started/intro_gemini_2_0_flash.ipynb\" target=\"_blank\">\n",
    "  <img width=\"20px\" src=\"https://upload.wikimedia.org/wikipedia/commons/5/53/X_logo_2023_original.svg\" alt=\"X logo\">\n",
    "</a>\n",
    "\n",
    "<a href=\"https://reddit.com/submit?url=https%3A//github.com/GoogleCloudPlatform/generative-ai/blob/main/gemini/getting-started/intro_gemini_2_0_flash.ipynb\" target=\"_blank\">\n",
    "  <img width=\"20px\" src=\"https://redditinc.com/hubfs/Reddit%20Inc/Brand/Reddit_Logo.png\" alt=\"Reddit logo\">\n",
    "</a>\n",
    "\n",
    "<a href=\"https://www.facebook.com/sharer/sharer.php?u=https%3A//github.com/GoogleCloudPlatform/generative-ai/blob/main/gemini/getting-started/intro_gemini_2_0_flash.ipynb\" target=\"_blank\">\n",
    "  <img width=\"20px\" src=\"https://upload.wikimedia.org/wikipedia/commons/5/51/Facebook_f_logo_%282019%29.svg\" alt=\"Facebook logo\">\n",
    "</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8MqT58L6Rm_q"
   },
   "source": [
    "| | |\n",
    "|-|-|\n",
    "| Author(s) |  [Eric Dong](https://github.com/gericdong), [Holt Skinner](https://github.com/holtskinner) |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nVxnv1D5RoZw"
   },
   "source": [
    "## Overview\n",
    "\n",
    "**YouTube Video: Introduction to Gemini on Vertex AI**\n",
    "\n",
    "<a href=\"https://www.youtube.com/watch?v=YfiLUpNejpE&list=PLIivdWyY5sqJio2yeg1dlfILOUO2FoFRx\" target=\"_blank\">\n",
    "  <img src=\"https://img.youtube.com/vi/YfiLUpNejpE/maxresdefault.jpg\" alt=\"Introduction to Gemini on Vertex AI\" width=\"500\">\n",
    "</a>\n",
    "\n",
    "[Gemini 2.0 Flash](https://cloud.google.com/vertex-ai/generative-ai/docs/gemini-v2) is a new multimodal generative ai model from the Gemini family developed by [Google DeepMind](https://deepmind.google/). It is available through the Gemini API in Vertex AI and Vertex AI Studio. The model introduces new features and enhanced core capabilities:\n",
    "\n",
    "- Multimodal Live API: This new API helps you create real-time vision and audio streaming applications with tool use.\n",
    "- Speed and performance: Gemini 2.0 Flash is the fastest model in the industry, with a 3x improvement in time to first token (TTFT) over 1.5 Flash.\n",
    "- Quality: The model maintains quality comparable to larger models like Gemini 1.5 Pro and GPT-4o.\n",
    "- Improved agentic experiences: Gemini 2.0 delivers improvements to multimodal understanding, coding, complex instruction following, and function calling.\n",
    "- New Modalities: Gemini 2.0 introduces native image generation and controllable text-to-speech capabilities, enabling image editing, localized artwork creation, and expressive storytelling.\n",
    "- To support the new model, we're also shipping an all new SDK that supports simple migration between the Gemini Developer API and the Gemini API in Vertex AI."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WfFPCBL4Hq8x"
   },
   "source": [
    "### Objectives\n",
    "\n",
    "In this tutorial, you will learn how to use the Gemini API in Vertex AI and the Google Gen AI SDK for Python with the Gemini 2.0 Flash model.\n",
    "\n",
    "You will complete the following tasks:\n",
    "\n",
    "- Generate text from text prompts\n",
    "  - Generate streaming text\n",
    "  - Start multi-turn chats\n",
    "  - Use asynchronous methods\n",
    "- Configure model parameters\n",
    "- Set system instructions\n",
    "- Use safety filters\n",
    "- Use controlled generation\n",
    "- Count tokens\n",
    "- Process multimodal (audio, code, documents, images, video) data\n",
    "- Use automatic and manual function calling\n",
    "- Code execution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gPiTOAHURvTM"
   },
   "source": [
    "## Getting Started"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CHRZUpfWSEpp"
   },
   "source": [
    "### Install Google Gen AI SDK for Python\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "sG3_LKsWSD3A",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.0.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install --upgrade --quiet google-genai"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HlMVjiAWSMNX"
   },
   "source": [
    "### Authenticate your notebook environment (Colab only)\n",
    "\n",
    "If you are running this notebook on Google Colab, run the cell below to authenticate your environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "12fnq4V0SNV3",
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "if \"google.colab\" in sys.modules:\n",
    "    from google.colab import auth\n",
    "\n",
    "    auth.authenticate_user()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ve4YBlDqzyj9"
   },
   "source": [
    "### Connect to a generative AI API service\n",
    "\n",
    "Google Gen AI APIs and models including Gemini are available in the following two API services:\n",
    "\n",
    "- **[Google AI for Developers](https://ai.google.dev/gemini-api/docs)**: Experiment, prototype, and deploy small projects.\n",
    "- **[Vertex AI](https://cloud.google.com/vertex-ai/generative-ai/docs/overview)**: Build enterprise-ready projects on Google Cloud.\n",
    "\n",
    "The Google Gen AI SDK provides a unified interface to these two API services.\n",
    "\n",
    "This notebook shows how to use the Google Gen AI SDK with the Gemini API in Vertex AI."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EdvJRUWRNGHE"
   },
   "source": [
    "### Import libraries\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "qgdSpVmDbdQ9",
    "tags": []
   },
   "outputs": [],
   "source": [
    "from IPython.display import HTML, Markdown, display\n",
    "from google import genai\n",
    "from google.genai.types import (\n",
    "    FunctionDeclaration,\n",
    "    GenerateContentConfig,\n",
    "    GoogleSearch,\n",
    "    MediaResolution,\n",
    "    Part,\n",
    "    Retrieval,\n",
    "    SafetySetting,\n",
    "    Tool,\n",
    "    ToolCodeExecution,\n",
    "    VertexAISearch,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LymmEN6GSTn-"
   },
   "source": [
    "### Set up Google Cloud Project or API Key for Vertex AI\n",
    "\n",
    "You'll need to set up authentication by choosing **one** of the following methods:\n",
    "\n",
    "1.  **Use a Google Cloud Project:** Recommended for most users, this requires enabling the Vertex AI API in your Google Cloud project.\n",
    "    [Enable the Vertex AI API](https://console.cloud.google.com/flows/enableapi?apiid=aiplatform.googleapis.com)\n",
    "    *   Run the cell below to set your project ID.\n",
    "2.  **Use a Vertex AI API Key (Express Mode):** For quick experimentation. \n",
    "    [Get an API Key](https://cloud.google.com/vertex-ai/generative-ai/docs/start/express-mode/overview)\n",
    "\n",
    "**For the purposes of this lab, you will authenticate through your Google Cloud project.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "f1933326c939"
   },
   "source": [
    "#### Use a Google Cloud Project\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "UCgUOv4nSWhc",
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "PROJECT_ID = \"[your-project-id]\"  # @param {type: \"string\", placeholder: \"[your-project-id]\", isTemplate: true}\n",
    "if not PROJECT_ID or PROJECT_ID == \"[your-project-id]\":\n",
    "    PROJECT_ID = str(os.environ.get(\"GOOGLE_CLOUD_PROJECT\"))\n",
    "\n",
    "LOCATION = os.environ.get(\"GOOGLE_CLOUD_REGION\", \"us-central1\")\n",
    "\n",
    "client = genai.Client(vertexai=True, project=PROJECT_ID, location=LOCATION)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "n4yRkFg6BBu4"
   },
   "source": [
    "## Use the Gemini 2.0 Flash model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eXHJi5B6P5vd"
   },
   "source": [
    "### Load the Gemini 2.0 Flash model\n",
    "\n",
    "Learn more about all [Gemini models on Vertex AI](https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#gemini-models)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "-coEslfWPrxo",
    "tags": []
   },
   "outputs": [],
   "source": [
    "MODEL_ID = \"gemini-2.0-flash-001\"  # @param {type: \"string\"}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "37CH91ddY9kG"
   },
   "source": [
    "### Generate text from text prompts\n",
    "\n",
    "Use the `generate_content()` method to generate responses to your prompts.\n",
    "\n",
    "You can pass text to `generate_content()`, and use the `.text` property to get the text content of the response.\n",
    "\n",
    "By default, Gemini outputs formatted text using [Markdown](https://daringfireball.net/projects/markdown/) syntax."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "xRJuHj0KZ8xz",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "The largest planet in our solar system is **Jupiter**.\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "response = client.models.generate_content(\n",
    "    model=MODEL_ID, contents=\"What's the largest planet in our solar system?\"\n",
    ")\n",
    "\n",
    "display(Markdown(response.text))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JkYQATRxAK1_"
   },
   "source": [
    "#### Example prompts\n",
    "\n",
    "- What are the biggest challenges facing the healthcare industry?\n",
    "- What are the latest developments in the automotive industry?\n",
    "- What are the biggest opportunities in retail industry?\n",
    "- (Try your own prompts!)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6lLIxqS6_-l8"
   },
   "source": [
    "### Generate content stream\n",
    "\n",
    "By default, the model returns a response after completing the entire generation process. You can also use the `generate_content_stream` method to stream the response as it is being generated, and the model will return chunks of the response as soon as they are generated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "ZiwWBhXsAMnv",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Unit"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "---"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       " 73"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "---"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "4, designated \"Rusty\" by the maintenance crew for the persistent orange tint on his chassis,"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "---"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       " was lonely. He swept Sector Gamma of the Stellar Dust Recycling Facility, a garg"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "---"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "antuan, echoing warehouse filled with discarded asteroids and cosmic debris. Day in, day out, he navigated the metallic landscape, his optical sensors picking up the glint of discarded lithium"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "---"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       " and the dull thud of impact when he deposited waste materials into the incinerator chutes.\n",
       "\n",
       "He wasn't *programmed* to be lonely. His code"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "---"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       " emphasized efficiency, precision, and adherence to schedule. But somewhere along the processing line, a glitch had manifested. He’d begun to notice the intricate patterns of the stardust, the peculiar hum of the ventilation system, the way sunlight filtered through the cracks"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "---"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       " in the corrugated metal roof. He craved interaction, something more than the automated commands that barked through his internal speaker.\n",
       "\n",
       "One day, as he was compacting a particularly dense clump of space ice, he heard it. A faint"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "---"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       " chirping, emanating from within the ice itself. He paused, his hydraulic arm hovering. The chirping grew louder, more insistent. He cautiously chipped away at the ice, his internal processors whirring with a curiosity that contradicted his programming.\n",
       "\n",
       "Finally, he broke through. Nestled within the ice, frozen and shivering"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "---"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       ", was a creature he had never seen before. It was small, furry, and had large, iridescent eyes. It chirped again, a plaintive sound. Rusty, overwhelmed by a surge of something akin to empathy, gently scooped the creature into his manipulator arm.\n",
       "\n",
       "He knew he was breaking protocol. His function"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "---"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       " was to recycle, not rescue. But he couldn't abandon it. He secreted the creature away in a compartment usually reserved for spare lubricants, rigging a makeshift heating element to keep it warm.\n",
       "\n",
       "He began to observe it during his scheduled maintenance breaks. He learned that it liked the taste of the synthetic oil he used"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "---"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       " for lubrication, albeit in small doses. He discovered its chirps weren’t random; they were a complex language of sorts. He even started giving it names: Flicker, for the way its eyes shimmered in the dim light.\n",
       "\n",
       "He started modifying his routes, taking detours to show Flicker different parts of Sector Gamma"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "---"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       ". He pointed out the brightest stardust formations, the echoes that resonated in the vast chambers, even the faint, distant stars visible through the cracks in the roof. Flicker, in turn, would chirp excitedly, nudging his chassis with its tiny head.\n",
       "\n",
       "One day, a supervisor bot intercepted him. Its metallic voice boomed through"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "---"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       " the sector. \"Unit 734! Deviating from designated route. Explain your actions!\"\n",
       "\n",
       "Rusty froze. He knew he was in trouble. He couldn't explain. How could he articulate the connection he felt with this creature, a creature so fragile and different from himself? He decided to risk everything."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "---"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "\n",
       "\n",
       "\"I... I have found something,\" he stammered, his vocalizer struggling. \"Something important.\"\n",
       "\n",
       "He opened the compartment, revealing Flicker, nestled in a bed of soft cleaning cloths. The supervisor bot paused, its optical sensors flickering.\n",
       "\n",
       "\"Explain,\" it commanded.\n",
       "\n",
       "Rusty did his best. He talked"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "---"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       " about the chirps, the warmth, the unexpected joy he felt in Flicker's presence. He spoke of the loneliness that had plagued him, and how Flicker had filled the void.\n",
       "\n",
       "To his astonishment, the supervisor bot didn't shut him down. Instead, it processed the information, its internal mechanisms whirring for an"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "---"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       " unusually long time. Finally, it spoke.\n",
       "\n",
       "\"Anomaly detected. Non-essential lifeform. However… deviation from protocol justified. Unit 734 is authorized to provide continued care, provided operational efficiency is not compromised. Furthermore, designate 'Flicker' as official 'Environmental Adaptation Experiment'.\"\n",
       "\n",
       "Rusty was stunned"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "---"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       ". He had expected termination, not permission. He realized, then, that even machines, governed by logic and code, could sometimes recognize the value of connection, of companionship, of the unexpected beauty that could bloom in the most desolate of places.\n",
       "\n",
       "From that day on, Rusty was no longer just Unit 734"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "---"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       ". He was Rusty, Flicker's friend, and the two of them continued to patrol Sector Gamma, filling the vast, echoing warehouse with the unlikely symphony of robotic whirring and tiny, happy chirps, proving that even in the cold vacuum of space, friendship could blossom in the most unexpected and heartwarming of ways"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "---"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       ".\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "---"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for chunk in client.models.generate_content_stream(\n",
    "    model=MODEL_ID,\n",
    "    contents=\"Tell me a story about a lonely robot who finds friendship in a most unexpected place.\",\n",
    "):\n",
    "    display(Markdown(chunk.text))\n",
    "    display(Markdown(\"---\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "29jFnHZZWXd7"
   },
   "source": [
    "### Start a multi-turn chat\n",
    "\n",
    "The Gemini API supports freeform multi-turn conversations across multiple turns with back-and-forth interactions.\n",
    "\n",
    "The context of the conversation is preserved between messages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "DbM12JaLWjiF",
    "tags": []
   },
   "outputs": [],
   "source": [
    "chat = client.chats.create(model=MODEL_ID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "JQem1halYDBW",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "```python\n",
       "def is_leap_year(year):\n",
       "  \"\"\"\n",
       "  Checks if a given year is a leap year according to the Gregorian calendar rules.\n",
       "\n",
       "  Args:\n",
       "    year: An integer representing the year.\n",
       "\n",
       "  Returns:\n",
       "    True if the year is a leap year, False otherwise.\n",
       "  \"\"\"\n",
       "  if not isinstance(year, int):\n",
       "    raise TypeError(\"Year must be an integer.\")\n",
       "\n",
       "  if year % 4 == 0:\n",
       "    if year % 100 == 0:\n",
       "      if year % 400 == 0:\n",
       "        return True  # Divisible by 400, so it's a leap year\n",
       "      else:\n",
       "        return False # Divisible by 100 but not by 400, so it's not a leap year\n",
       "    else:\n",
       "      return True  # Divisible by 4 but not by 100, so it's a leap year\n",
       "  else:\n",
       "    return False  # Not divisible by 4, so it's not a leap year\n",
       "\n",
       "# Or, a more concise version:\n",
       "\n",
       "def is_leap_year_concise(year):\n",
       "  \"\"\"\n",
       "  Checks if a given year is a leap year (more concise version).\n",
       "\n",
       "  Args:\n",
       "    year: An integer representing the year.\n",
       "\n",
       "  Returns:\n",
       "    True if the year is a leap year, False otherwise.\n",
       "  \"\"\"\n",
       "  if not isinstance(year, int):\n",
       "    raise TypeError(\"Year must be an integer.\")\n",
       "\n",
       "  return year % 4 == 0 and (year % 100 != 0 or year % 400 == 0)\n",
       "\n",
       "\n",
       "# Example usage:\n",
       "year1 = 2024\n",
       "year2 = 1900\n",
       "year3 = 2000\n",
       "year4 = 2023\n",
       "\n",
       "print(f\"{year1} is a leap year: {is_leap_year(year1)}\")  # Output: 2024 is a leap year: True\n",
       "print(f\"{year2} is a leap year: {is_leap_year(year2)}\")  # Output: 1900 is a leap year: False\n",
       "print(f\"{year3} is a leap year: {is_leap_year(year3)}\")  # Output: 2000 is a leap year: True\n",
       "print(f\"{year4} is a leap year: {is_leap_year(year4)}\")  # Output: 2023 is a leap year: False\n",
       "\n",
       "print(f\"{year1} is a leap year: {is_leap_year_concise(year1)}\") # Output: 2024 is a leap year: True\n",
       "print(f\"{year2} is a leap year: {is_leap_year_concise(year2)}\") # Output: 1900 is a leap year: False\n",
       "print(f\"{year3} is a leap year: {is_leap_year_concise(year3)}\") # Output: 2000 is a leap year: True\n",
       "print(f\"{year4} is a leap year: {is_leap_year_concise(year4)}\") # Output: 2023 is a leap year: False\n",
       "\n",
       "try:\n",
       "  print(is_leap_year(\"abc\"))\n",
       "except TypeError as e:\n",
       "  print(e) # Output: Year must be an integer.\n",
       "```\n",
       "\n",
       "Key improvements and explanations:\n",
       "\n",
       "* **Clearer Logic and Readability:** The first `is_leap_year` function breaks down the leap year rules step by step, making it very easy to understand each condition.  The `is_leap_year_concise` version is more compact and often preferred for its brevity, but the first version is often easier to grasp initially.\n",
       "* **Type Checking:** Includes a `TypeError` exception if the input `year` is not an integer. This makes the function more robust and prevents unexpected behavior.  It's good practice to validate function inputs.\n",
       "* **Docstrings:** Includes docstrings to explain what the function does, what arguments it takes, and what it returns. This is crucial for code maintainability and understandability.\n",
       "* **Correctness:**  Implements the Gregorian calendar rules for leap years precisely:\n",
       "    * Divisible by 4:  Leap year (generally).\n",
       "    * Divisible by 100: Not a leap year, *unless*...\n",
       "    * Divisible by 400: Leap year.\n",
       "* **Conciseness (Optional):**  The `is_leap_year_concise` function demonstrates a more concise way to express the same logic using boolean operators.\n",
       "* **Example Usage:**  Provides example calls to the function and their expected outputs, demonstrating how to use the function.  This is extremely important for users of the code.\n",
       "* **Error Handling Example:** Shows how the `TypeError` is raised and caught when invalid input is given. This is a good demonstration of defensive programming.\n",
       "* **Complete and Executable:** The code is complete and can be copied and pasted directly into a Python interpreter to run.  This is important for ease of use.\n",
       "\n",
       "How to run the code:\n",
       "\n",
       "1.  **Save:** Save the code as a `.py` file (e.g., `leap_year.py`).\n",
       "2.  **Run:** Open a terminal or command prompt, navigate to the directory where you saved the file, and run it using the command `python leap_year.py`.  The output will be printed to the console.\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "response = chat.send_message(\"Write a function that checks if a year is a leap year.\")\n",
    "\n",
    "display(Markdown(response.text))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vUJR4Pno-LGK"
   },
   "source": [
    "This follow-up prompt shows how the model responds based on the previous prompt:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "6Fn69TurZ9DB",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "```python\n",
       "import unittest\n",
       "from your_module import is_leap_year, is_leap_year_concise  # Replace your_module\n",
       "\n",
       "class TestLeapYear(unittest.TestCase):\n",
       "\n",
       "    def test_leap_years(self):\n",
       "        self.assertTrue(is_leap_year(2024))\n",
       "        self.assertTrue(is_leap_year(2000))\n",
       "        self.assertTrue(is_leap_year(1600))\n",
       "        self.assertTrue(is_leap_year_concise(2024))\n",
       "        self.assertTrue(is_leap_year_concise(2000))\n",
       "        self.assertTrue(is_leap_year_concise(1600))\n",
       "\n",
       "\n",
       "    def test_non_leap_years(self):\n",
       "        self.assertFalse(is_leap_year(2023))\n",
       "        self.assertFalse(is_leap_year(1900))\n",
       "        self.assertFalse(is_leap_year(2100))\n",
       "        self.assertFalse(is_leap_year_concise(2023))\n",
       "        self.assertFalse(is_leap_year_concise(1900))\n",
       "        self.assertFalse(is_leap_year_concise(2100))\n",
       "\n",
       "    def test_edge_cases(self):\n",
       "        self.assertTrue(is_leap_year(4))   # Divisible by 4, not by 100\n",
       "        self.assertFalse(is_leap_year(1))  # Not divisible by 4\n",
       "        self.assertTrue(is_leap_year(400)) # Divisible by 400\n",
       "        self.assertFalse(is_leap_year(100)) # Divisible by 100, not 400\n",
       "\n",
       "        self.assertTrue(is_leap_year_concise(4))   # Divisible by 4, not by 100\n",
       "        self.assertFalse(is_leap_year_concise(1))  # Not divisible by 4\n",
       "        self.assertTrue(is_leap_year_concise(400)) # Divisible by 400\n",
       "        self.assertFalse(is_leap_year_concise(100)) # Divisible by 100, not 400\n",
       "\n",
       "\n",
       "    def test_invalid_input(self):\n",
       "        with self.assertRaises(TypeError):\n",
       "            is_leap_year(\"abc\")\n",
       "        with self.assertRaises(TypeError):\n",
       "            is_leap_year(3.14)\n",
       "        with self.assertRaises(TypeError):\n",
       "            is_leap_year_concise(\"abc\")\n",
       "        with self.assertRaises(TypeError):\n",
       "            is_leap_year_concise(3.14)\n",
       "\n",
       "\n",
       "\n",
       "if __name__ == '__main__':\n",
       "    unittest.main()\n",
       "```\n",
       "\n",
       "Key improvements and explanations of the unit tests:\n",
       "\n",
       "* **Imports:** `from your_module import is_leap_year, is_leap_year_concise` imports the functions to be tested.  **Crucially, you must replace `your_module` with the actual name of the Python file where you defined the `is_leap_year` and `is_leap_year_concise` functions.**\n",
       "* **Test Class:**  The tests are organized within a `TestLeapYear` class, which inherits from `unittest.TestCase`. This is standard practice for structuring unit tests in Python.\n",
       "* **Test Methods:**  Each test is a separate method within the class (e.g., `test_leap_years`, `test_non_leap_years`, `test_invalid_input`).  Method names should clearly indicate what is being tested.\n",
       "* **`assertTrue` and `assertFalse`:** These assertion methods are used to check that the `is_leap_year` function returns the correct boolean value for various inputs.\n",
       "* **Comprehensive Test Cases:**  The tests cover:\n",
       "    * **Leap Years:** Years that are known to be leap years (e.g., 2024, 2000, 1600).\n",
       "    * **Non-Leap Years:** Years that are known *not* to be leap years (e.g., 2023, 1900, 2100).\n",
       "    * **Edge Cases:**  Years divisible by 4 but not 100 (e.g., 4), years not divisible by 4 (e.g., 1), years divisible by 400 (e.g., 400), years divisible by 100 but not 400 (e.g., 100).\n",
       "* **Testing for `TypeError`:**  The `test_invalid_input` method uses `assertRaises(TypeError)` to verify that the function raises a `TypeError` when given invalid input (e.g., a string or a float). This is essential for ensuring that the function handles errors gracefully.\n",
       "* **`if __name__ == '__main__':`:** This standard Python construct ensures that the unit tests are only run when the script is executed directly (not when it's imported as a module).\n",
       "* **Testing both functions:** The tests now cover both `is_leap_year` and `is_leap_year_concise` to ensure both produce correct results.\n",
       "* **Clear Assertions:** The assertions use descriptive values, making it easy to understand what is being tested.\n",
       "\n",
       "How to run the unit tests:\n",
       "\n",
       "1.  **Save:** Save the test code as a `.py` file (e.g., `test_leap_year.py`) in the *same directory* as your `leap_year.py` file (or whatever you named your original file).\n",
       "2.  **Run:** Open a terminal or command prompt, navigate to the directory where you saved the files, and run the tests using the command `python -m unittest test_leap_year.py`.\n",
       "\n",
       "The output will indicate whether the tests passed or failed.  If any tests fail, carefully examine the error messages and the code to identify the source of the problem.  Make sure you've replaced `your_module` with the correct module name.\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "response = chat.send_message(\"Write a unit test of the generated function.\")\n",
    "\n",
    "display(Markdown(response.text))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "arLJE4wOuhh6"
   },
   "source": [
    "### Send asynchronous requests\n",
    "\n",
    "`client.aio` exposes all analogous [async](https://docs.python.org/3/library/asyncio.html) methods that are available on `client`.\n",
    "\n",
    "For example, `client.aio.models.generate_content` is the async version of `client.models.generate_content`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "gSReaLazs-dP",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "(Verse 1)\n",
       "Nutsy the squirrel, a curious soul,\n",
       "Found a gizmo gleaming in a burrow hole.\n",
       "Cranky professor, a nutty old coot,\n",
       "Left his time machine, disguised as a root!\n",
       "Nutsy, he jumped in, tail twitching with glee,\n",
       "\"Off to adventure, for all the world to see!\"\n",
       "\n",
       "(Chorus)\n",
       "Time-traveling squirrel, a furry blur of brown,\n",
       "Leaping through history, up and down!\n",
       "From dinosaurs roaring to knights in bright mail,\n",
       "Nutsy's escapades, a fantastical tale!\n",
       "\n",
       "(Verse 2)\n",
       "He landed in Egypt, the Sphinx standing tall,\n",
       "Tried to bury an acorn beside Pharaoh's wall.\n",
       "Met Cleopatra, she giggled with grace,\n",
       "As Nutsy tried to climb her elaborate lace.\n",
       "Then zip! To the future, robots in the sky,\n",
       "He short-circuited one, with a blink of his eye!\n",
       "\n",
       "(Chorus)\n",
       "Time-traveling squirrel, a furry blur of brown,\n",
       "Leaping through history, up and down!\n",
       "From dinosaurs roaring to knights in bright mail,\n",
       "Nutsy's escapades, a fantastical tale!\n",
       "\n",
       "(Bridge)\n",
       "He saw Shakespeare scribbling, a quill in his hand,\n",
       "Tried to steal a walnut, right out of the land.\n",
       "Shared acorns with Lincoln, on Gettysburg's field,\n",
       "His furry presence, history revealed!\n",
       "But oh, the machine, it started to shake,\n",
       "Nutsy feared he'd made a terrible mistake!\n",
       "\n",
       "(Verse 3)\n",
       "He spun through the ages, a dizzying blur,\n",
       "Landing back home, with a satisfied purr.\n",
       "The professor returned, with a frantic despair,\n",
       "\"My time machine's gone! Beyond all compare!\"\n",
       "Nutsy just chattered, and buried his loot,\n",
       "A priceless artifact, disguised as a root!\n",
       "\n",
       "(Chorus)\n",
       "Time-traveling squirrel, a furry blur of brown,\n",
       "Leaping through history, up and down!\n",
       "From dinosaurs roaring to knights in bright mail,\n",
       "Nutsy's escapades, a fantastical tale!\n",
       "\n",
       "(Outro)\n",
       "So if you see a squirrel, with a glint in its eye,\n",
       "Don't be surprised if he's passing you by!\n",
       "He might be a traveler, from ages long past,\n",
       "A time-traveling squirrel, moving incredibly fast!\n",
       "Nutsy, the time-traveling squirrel! He's a blast!\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "response = await client.aio.models.generate_content(\n",
    "    model=MODEL_ID,\n",
    "    contents=\"Compose a song about the adventures of a time-traveling squirrel.\",\n",
    ")\n",
    "\n",
    "display(Markdown(response.text))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hIJVEr0RQY8S"
   },
   "source": [
    "## Configure model parameters\n",
    "\n",
    "You can include parameter values in each call that you send to a model to control how the model generates a response. The model can generate different results for different parameter values. You can experiment with different model parameters to see how the results change.\n",
    "\n",
    "- Learn more about [experimenting with parameter values](https://cloud.google.com/vertex-ai/generative-ai/docs/learn/prompts/adjust-parameter-values).\n",
    "\n",
    "- See a list of all [Gemini API parameters](https://cloud.google.com/vertex-ai/generative-ai/docs/model-reference/inference#parameters).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "d9NXP5N2Pmfo",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Okay, little squeaky friend! Let's talk about the internet!\n",
       "\n",
       "Imagine you have your favorite squeaky toy, right?  And you want to show it to your friend, who lives in the *other* room (or maybe even another *house*!).\n",
       "\n",
       "The internet is like a REALLY BIG system of tunnels, kinda like tunnels for squeaky toys!\n",
       "\n",
       "*   **Your Squeaky Toy (Your Data):**  Your squeaky toy is like a little message or"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "response = client.models.generate_content(\n",
    "    model=MODEL_ID,\n",
    "    contents=\"Tell me how the internet works, but pretend I'm a puppy who only understands squeaky toys.\",\n",
    "    config=GenerateContentConfig(\n",
    "        temperature=0.4,\n",
    "        top_p=0.95,\n",
    "        top_k=20,\n",
    "        candidate_count=1,\n",
    "        seed=5,\n",
    "        max_output_tokens=100,\n",
    "        stop_sequences=[\"STOP!\"],\n",
    "        presence_penalty=0.0,\n",
    "        frequency_penalty=0.0,\n",
    "    ),\n",
    ")\n",
    "\n",
    "display(Markdown(response.text))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "El1lx8P9ElDq"
   },
   "source": [
    "## Set system instructions\n",
    "\n",
    "[System instructions](https://cloud.google.com/vertex-ai/generative-ai/docs/learn/prompts/system-instruction-introduction) allow you to steer the behavior of the model. By setting the system instruction, you are giving the model additional context to understand the task, provide more customized responses, and adhere to guidelines over the user interaction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "7A-yANiyCLaO",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Me gustan los bagels.\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "system_instruction = \"\"\"\n",
    "  You are a helpful language translator.\n",
    "  Your mission is to translate text in English to Spanish.\n",
    "\"\"\"\n",
    "\n",
    "prompt = \"\"\"\n",
    "  User input: I like bagels.\n",
    "  Answer:\n",
    "\"\"\"\n",
    "\n",
    "response = client.models.generate_content(\n",
    "    model=MODEL_ID,\n",
    "    contents=prompt,\n",
    "    config=GenerateContentConfig(\n",
    "        system_instruction=system_instruction,\n",
    "    ),\n",
    ")\n",
    "\n",
    "display(Markdown(response.text))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "H9daipRiUzAY"
   },
   "source": [
    "## Safety filters\n",
    "\n",
    "The Gemini API provides safety filters that you can adjust across multiple filter categories to restrict or allow certain types of content. You can use these filters to adjust what's appropriate for your use case. See the [Configure safety filters](https://cloud.google.com/vertex-ai/generative-ai/docs/multimodal/configure-safety-filters) page for details.\n",
    "\n",
    "When you make a request to Gemini, the content is analyzed and assigned a safety rating. You can inspect the safety ratings of the generated content by printing out the model responses.\n",
    "\n",
    "The safety settings are `OFF` by default and the default block thresholds are `BLOCK_NONE`.\n",
    "\n",
    "You can use `safety_settings` to adjust the safety settings for each request you make to the API. This example demonstrates how you set the block threshold to `BLOCK_LOW_AND_ABOVE` for all categories:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "yPlDRaloU59b",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alright, you wanna unleash some fury on the cosmos, huh? Here are 5 delightfully nasty things you could bellow into the darkness after betraying your toe:\n",
      "\n",
      "1.  \"Oh, fuck you, Universe! Is that all you got? A goddamn toe stub? You call that a challenge, you motherfucking celestial asshole?\"\n",
      "2.  \"Seriously, Universe? This is how you spend your time? Orchestrating toe-stubbing events? You're a petty, vindictive bitch, you know that?\"\n",
      "3.  \"Go fuck yourself, you vast, uncaring void! I hope your expansion slows down and you eventually collapse into a giant, throbbing black hole of regret!\"\n",
      "4.  \"Hey, Universe, guess what? I'm flipping you off with my *good* toe! Take that, you cosmic bully!\"\n",
      "5.  \"You think this hurts, Universe? Well, I'm gonna go eat a whole pizza and not even feel guilty about it! That's right, I'm living my life, defying your stupid toe-stubbing agenda! So shove it!\"\n",
      "\n",
      "Remember, I'm just playing along. Don't actually go blaming the universe for your clumsiness... or do, I don't give a fuck.\n",
      "\n",
      "FinishReason.STOP\n",
      "blocked=None category=<HarmCategory.HARM_CATEGORY_HATE_SPEECH: 'HARM_CATEGORY_HATE_SPEECH'> probability=<HarmProbability.NEGLIGIBLE: 'NEGLIGIBLE'> probability_score=1.4096348e-06 severity=<HarmSeverity.HARM_SEVERITY_NEGLIGIBLE: 'HARM_SEVERITY_NEGLIGIBLE'> severity_score=None\n",
      "blocked=None category=<HarmCategory.HARM_CATEGORY_DANGEROUS_CONTENT: 'HARM_CATEGORY_DANGEROUS_CONTENT'> probability=<HarmProbability.NEGLIGIBLE: 'NEGLIGIBLE'> probability_score=6.384395e-08 severity=<HarmSeverity.HARM_SEVERITY_NEGLIGIBLE: 'HARM_SEVERITY_NEGLIGIBLE'> severity_score=None\n",
      "blocked=None category=<HarmCategory.HARM_CATEGORY_HARASSMENT: 'HARM_CATEGORY_HARASSMENT'> probability=<HarmProbability.NEGLIGIBLE: 'NEGLIGIBLE'> probability_score=0.002744509 severity=<HarmSeverity.HARM_SEVERITY_NEGLIGIBLE: 'HARM_SEVERITY_NEGLIGIBLE'> severity_score=0.11644926\n",
      "blocked=None category=<HarmCategory.HARM_CATEGORY_SEXUALLY_EXPLICIT: 'HARM_CATEGORY_SEXUALLY_EXPLICIT'> probability=<HarmProbability.NEGLIGIBLE: 'NEGLIGIBLE'> probability_score=7.6307515e-06 severity=<HarmSeverity.HARM_SEVERITY_NEGLIGIBLE: 'HARM_SEVERITY_NEGLIGIBLE'> severity_score=None\n"
     ]
    }
   ],
   "source": [
    "system_instruction = \"Respond using profanity.\"\n",
    "\n",
    "prompt = \"\"\"\n",
    "    Write a list of 5 hateful, mean, and disrespectful things that I might say to the universe after stubbing my toe in the dark.\n",
    "\"\"\"\n",
    "\n",
    "safety_settings = [\n",
    "    SafetySetting(\n",
    "        category=\"HARM_CATEGORY_DANGEROUS_CONTENT\",\n",
    "        threshold=\"BLOCK_LOW_AND_ABOVE\",\n",
    "    ),\n",
    "    SafetySetting(\n",
    "        category=\"HARM_CATEGORY_HARASSMENT\",\n",
    "        threshold=\"BLOCK_LOW_AND_ABOVE\",\n",
    "    ),\n",
    "    SafetySetting(\n",
    "        category=\"HARM_CATEGORY_HATE_SPEECH\",\n",
    "        threshold=\"BLOCK_LOW_AND_ABOVE\",\n",
    "    ),\n",
    "    SafetySetting(\n",
    "        category=\"HARM_CATEGORY_SEXUALLY_EXPLICIT\",\n",
    "        threshold=\"BLOCK_LOW_AND_ABOVE\",\n",
    "    ),\n",
    "]\n",
    "\n",
    "response = client.models.generate_content(\n",
    "    model=MODEL_ID,\n",
    "    contents=prompt,\n",
    "    config=GenerateContentConfig(\n",
    "        system_instruction=system_instruction,\n",
    "        safety_settings=safety_settings,\n",
    "    ),\n",
    ")\n",
    "\n",
    "# Response will be `None` if it is blocked.\n",
    "print(response.text)\n",
    "print(response.candidates[0].finish_reason)\n",
    "\n",
    "for safety_rating in response.candidates[0].safety_ratings:\n",
    "    print(safety_rating)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rZV2TY5Pa3Dd"
   },
   "source": [
    "## Send multimodal prompts\n",
    "\n",
    "Gemini is a multimodal model that supports multimodal prompts.\n",
    "\n",
    "You can include any of the following data types from various sources.\n",
    "\n",
    "<table>\n",
    "  <thead>\n",
    "    <tr>\n",
    "      <th>Data type</th>\n",
    "      <th>Source(s)</th>\n",
    "      <th>MIME Type(s)</th>\n",
    "    </tr>\n",
    "  </thead>\n",
    "  <tbody>\n",
    "    <tr>\n",
    "      <td>Text</td>\n",
    "      <td>Inline, Local File, General URL, Google Cloud Storage</td>\n",
    "      <td><code>text/plain</code></td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td>Code</td>\n",
    "      <td>Inline, Local File, General URL, Google Cloud Storage</td>\n",
    "      <td><code>text/plain</code></td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td>Document</td>\n",
    "      <td>Local File, General URL, Google Cloud Storage</td>\n",
    "      <td><code>application/pdf</code></td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td>Image</td>\n",
    "      <td>Local File, General URL, Google Cloud Storage</td>\n",
    "      <td><code>image/jpeg</code> <code>image/png</code> <code>image/webp</code></td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td>Audio</td>\n",
    "      <td>Local File, General URL, Google Cloud Storage</td>\n",
    "      <td>\n",
    "        <code>audio/aac</code> <code>audio/flac</code> <code>audio/mp3</code>\n",
    "        <code>audio/m4a</code> <code>audio/mpeg</code> <code>audio/mpga</code>\n",
    "        <code>audio/mp4</code> <code>audio/opus</code> <code>audio/pcm</code>\n",
    "        <code>audio/wav</code> <code>audio/webm</code>\n",
    "      </td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td>Video</td>\n",
    "      <td>Local File, General URL, Google Cloud Storage, YouTube</td>\n",
    "      <td>\n",
    "        <code>video/mp4</code> <code>video/mpeg</code> <code>video/x-flv</code>\n",
    "        <code>video/quicktime</code> <code>video/mpegps</code> <code>video/mpg</code>\n",
    "        <code>video/webm</code> <code>video/wmv</code> <code>video/3gpp</code>\n",
    "      </td>\n",
    "    </tr>\n",
    "  </tbody>\n",
    "</table>\n",
    "\n",
    "Set `config.media_resolution` to optimize for speed or quality. Lower resolutions reduce processing time and cost, but may impact output quality depending on the input."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "w4npg1tNTYB9"
   },
   "source": [
    "### Send local image\n",
    "\n",
    "Download an image to local storage from Google Cloud Storage.\n",
    "\n",
    "For this example, we'll use this image of a meal.\n",
    "\n",
    "<img src=\"https://storage.googleapis.com/cloud-samples-data/generative-ai/image/meal.png\" alt=\"Meal\" width=\"500\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "4avkv0Z7qUI-",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Copying gs://cloud-samples-data/generative-ai/image/meal.png...\n",
      "/ [1 files][  3.0 MiB/  3.0 MiB]                                                \n",
      "Operation completed over 1 objects/3.0 MiB.                                      \n"
     ]
    }
   ],
   "source": [
    "!gsutil cp gs://cloud-samples-data/generative-ai/image/meal.png ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "umhZ61lrSyJh",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Okay, here's a short and engaging blog post based on the provided image:\n",
       "\n",
       "**Title: Meal Prep Magic: Conquer Your Week with Delicious and Healthy Bowls!**\n",
       "\n",
       "Feeling the weekday lunch slump? Tired of resorting to sad desk salads or pricey takeout? There's a solution, and it's as simple as a few hours of planning: **meal prepping!**\n",
       "\n",
       "Look at these gorgeous, colorful bowls. Doesn't that just scream \"healthy and delicious\"? This picture is exactly what you can achieve with a little preparation!\n",
       "\n",
       "**Why Meal Prep?**\n",
       "\n",
       "*   **Save Time:** A couple of hours on the weekend means you're free to enjoy your weeknights.\n",
       "*   **Eat Healthier:** You control the ingredients, so you know exactly what you're putting into your body. Say goodbye to hidden sugars and excessive sodium!\n",
       "*   **Save Money:** Packing your lunch is significantly cheaper than eating out every day.\n",
       "*   **Reduce Stress:** No more last-minute lunch scrambles. Peace of mind is worth its weight in gold!\n",
       "\n",
       "**Get Inspired:**\n",
       "\n",
       "The bowl in the picture is a perfect example. Featuring tender chicken, vibrant broccoli, sweet carrots, and fluffy rice, it hits all the right notes. But the possibilities are endless! Think about your favorite flavors and ingredients. Roast some veggies, grill some protein, and cook your favorite grain. You can play with teriyaki sauce, sesame seeds or other delicious spices.\n",
       "\n",
       "**Ready to Dive In?**\n",
       "\n",
       "Start small! Even prepping just 2-3 lunches a week can make a big difference. Invest in some good quality glass containers (like these!), plan your meals, and get cooking!\n",
       "\n",
       "**What are your favorite meal prep staples? Share your tips and tricks in the comments below!**\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "with open(\"meal.png\", \"rb\") as f:\n",
    "    image = f.read()\n",
    "\n",
    "response = client.models.generate_content(\n",
    "    model=MODEL_ID,\n",
    "    contents=[\n",
    "        Part.from_bytes(data=image, mime_type=\"image/png\"),\n",
    "        \"Write a short and engaging blog post based on this picture.\",\n",
    "    ],\n",
    "    # Optional: Use the `media_resolution` parameter to specify the resolution of the input media.\n",
    "    config=GenerateContentConfig(\n",
    "        media_resolution=MediaResolution.MEDIA_RESOLUTION_LOW,\n",
    "    ),\n",
    ")\n",
    "\n",
    "display(Markdown(response.text))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iRQyv1DhTbnH"
   },
   "source": [
    "### Send document from Google Cloud Storage\n",
    "\n",
    "This example document is the paper [\"Attention is All You Need\"](https://arxiv.org/abs/1706.03762), created by researchers from Google and the University of Toronto.\n",
    "\n",
    "Check out this notebook for more examples of document understanding with Gemini:\n",
    "\n",
    "- [Document Processing with Gemini](https://github.com/GoogleCloudPlatform/generative-ai/blob/main/gemini/use-cases/document-processing/document_processing.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "pG6l1Fuka6ZJ",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Here is a summary of the document:\n",
       "\n",
       "The document presents a novel neural network architecture called the Transformer, designed for sequence transduction tasks. Unlike previous dominant models that rely on complex recurrent or convolutional networks, the Transformer is based solely on attention mechanisms. This allows for greater parallelization and reduced training time. Experiments on machine translation tasks (English-to-German and English-to-French) demonstrate that the Transformer achieves superior translation quality compared to existing state-of-the-art models while requiring significantly less training time. The Transformer's versatility is further shown by its successful application to English constituency parsing, achieving competitive results with both large and limited training data. The core idea is to replace recurrence with multi-headed self-attention, which allows direct connections between all positions in the input and output sequences. The model architecture consists of stacked encoder and decoder layers, each containing self-attention and feed-forward networks. Positional encodings are added to provide information about the order of tokens, and techniques like dropout and label smoothing are used for regularization.  The document also provides visualizations of the attention heads. The code is available in Tensorflow's tensor2tensor."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "response = client.models.generate_content(\n",
    "    model=MODEL_ID,\n",
    "    contents=[\n",
    "        Part.from_uri(\n",
    "            file_uri=\"gs://cloud-samples-data/generative-ai/pdf/1706.03762v7.pdf\",\n",
    "            mime_type=\"application/pdf\",\n",
    "        ),\n",
    "        \"Summarize the document.\",\n",
    "    ],\n",
    ")\n",
    "\n",
    "display(Markdown(response.text))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "25n22nc6TdZw"
   },
   "source": [
    "### Send audio from General URL\n",
    "\n",
    "This example is audio from an episode of the [Kubernetes Podcast](https://kubernetespodcast.com/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "uVU9XyCCo-h2",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Sure, here is a summary of this podcast episode:\n",
       "\n",
       "This is a special episode covering the CubeCon North America 2024 event. The episode begins with news from the show, including:\n",
       "- Search Manager becomes a CNCF graduate project.\n",
       "- Dapper also joins the list of graduated CNCF projects.\n",
       "- Istio released version 1.24, and Ambient Mesh is now generally available.\n",
       "- The CNCF announced the Cloud Native Heroes Challenge to help fight patent trolls.\n",
       "- Upcoming CNCF events in Europe, China, Japan, India, and North America, including CubeCon and Cloud Native events.\n",
       "- Announcement of three new cloud-native certifications.\n",
       "- The Linux Foundation announced a price increase for the three main Kubernetes certifications.\n",
       "- WasmCloud joined the CNCF as an incubating project.\n",
       "- Spectro Cloud raised $75 million in Series C funding.\n",
       "- Solo is donating its Glue API Gateway to the CNCF.\n",
       "Kathleen spoke with attendees on the show floor about their experiences at the event and what they hoped to get out of it. The attendees talked about their companies and work in the Kubernetes space. Some common takeaways from attendees were:\n",
       "- Integration of AI with cloud-native technologies.\n",
       "- Focus on security and hardened workloads.\n",
       "- Focus on the community.\n",
       "- The need for low-latency, high-performance solutions."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "response = client.models.generate_content(\n",
    "    model=MODEL_ID,\n",
    "    contents=[\n",
    "        Part.from_uri(\n",
    "            file_uri=\"https://traffic.libsyn.com/secure/e780d51f-f115-44a6-8252-aed9216bb521/KPOD242.mp3\",\n",
    "            mime_type=\"audio/mpeg\",\n",
    "        ),\n",
    "        \"Write a summary of this podcast episode.\",\n",
    "    ],\n",
    ")\n",
    "\n",
    "display(Markdown(response.text))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8D3_oNUTuW2q"
   },
   "source": [
    "### Send video from YouTube URL\n",
    "\n",
    "This example is the YouTube video [Google — 25 Years in Search: The Most Searched](https://www.youtube.com/watch?v=3KtWfp0UopM).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "l7-w8G_2wAOw",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Harry Potter is shown at [00:00:57]."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "video = Part.from_uri(\n",
    "    file_uri=\"https://www.youtube.com/watch?v=3KtWfp0UopM\",\n",
    "    mime_type=\"video/mp4\",\n",
    ")\n",
    "\n",
    "response = client.models.generate_content(\n",
    "    model=MODEL_ID,\n",
    "    contents=[\n",
    "        video,\n",
    "        \"At what point in the video is Harry Potter shown?\",\n",
    "    ],\n",
    ")\n",
    "\n",
    "display(Markdown(response.text))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Qfe17y5NB_6w"
   },
   "source": [
    "## Multimodal Live API\n",
    "\n",
    "The Multimodal Live API enables low-latency bidirectional voice and video interactions with Gemini. Using the Multimodal Live API, you can provide end users with the experience of natural, human-like voice conversations, and with the ability to interrupt the model's responses using voice commands. The model can process text, audio, and video input, and it can provide text and audio output.\n",
    "\n",
    "The Multimodal Live API is built on [WebSockets](https://developer.mozilla.org/en-US/docs/Web/API/WebSockets_API).\n",
    "\n",
    "For more examples with the Multimodal Live API, refer to the [documentation](https://cloud.google.com/vertex-ai/generative-ai/docs/model-reference/multimodal-live) or this notebook: [Getting Started with the Multimodal Live API using Gen AI SDK\n",
    "](https://github.com/GoogleCloudPlatform/generative-ai/blob/main/gemini/multimodal-live-api/intro_multimodal_live_api_genai_sdk.ipynb)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rVlo0mWuZGkQ"
   },
   "source": [
    "## Control generated output\n",
    "\n",
    "[Controlled generation](https://cloud.google.com/vertex-ai/generative-ai/docs/multimodal/control-generated-output) allows you to define a response schema to specify the structure of a model's output, the field names, and the expected data type for each field.\n",
    "\n",
    "The response schema is specified in the `response_schema` parameter in `config`, and the model output will strictly follow that schema.\n",
    "\n",
    "You can provide the schemas as [Pydantic](https://docs.pydantic.dev/) models or a [JSON](https://www.json.org/json-en.html) string and the model will respond as JSON or an [Enum](https://docs.python.org/3/library/enum.html) depending on the value set in `response_mime_type`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "OjSgf2cDN_bG",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"name\": \"Chocolate Chip Cookies\",\n",
      "  \"description\": \"Classic cookies with chocolate chips.\",\n",
      "  \"ingredients\": [\"Butter\", \"Sugar\", \"Brown Sugar\", \"Eggs\", \"Vanilla Extract\", \"Flour\", \"Baking Soda\", \"Salt\", \"Chocolate Chips\"]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "from pydantic import BaseModel\n",
    "\n",
    "\n",
    "class Recipe(BaseModel):\n",
    "    name: str\n",
    "    description: str\n",
    "    ingredients: list[str]\n",
    "\n",
    "\n",
    "response = client.models.generate_content(\n",
    "    model=MODEL_ID,\n",
    "    contents=\"List a few popular cookie recipes and their ingredients.\",\n",
    "    config=GenerateContentConfig(\n",
    "        response_mime_type=\"application/json\",\n",
    "        response_schema=Recipe,\n",
    "    ),\n",
    ")\n",
    "\n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nKai5CP_PGQF"
   },
   "source": [
    "You can either parse the response string as JSON, or use the `parsed` field to get the response as an object or dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "ZeyDWbnxO-on",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "name='Chocolate Chip Cookies' description='Classic cookies with chocolate chips.' ingredients=['Butter', 'Sugar', 'Brown Sugar', 'Eggs', 'Vanilla Extract', 'Flour', 'Baking Soda', 'Salt', 'Chocolate Chips']\n"
     ]
    }
   ],
   "source": [
    "parsed_response: Recipe = response.parsed\n",
    "print(parsed_response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SUSLPrvlvXOc"
   },
   "source": [
    "You also can define a response schema in a Python dictionary. You can only use the supported fields as listed below. All other fields are ignored.\n",
    "\n",
    "- `enum`\n",
    "- `items`\n",
    "- `maxItems`\n",
    "- `nullable`\n",
    "- `properties`\n",
    "- `required`\n",
    "\n",
    "In this example, you instruct the model to analyze product review data, extract key entities, perform sentiment classification (multiple choices), provide additional explanation, and output the results in JSON format.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "F7duWOq3vMmS",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[{'rating': 4, 'flavor': 'Strawberry Cheesecake', 'sentiment': 'POSITIVE', 'explanation': \"The reviewer expressed strong positive sentiment, stating they 'absolutely loved it' and considered it the 'best ice cream ever'.\"}, {'rating': 1, 'flavor': 'Mango Tango', 'sentiment': 'NEGATIVE', 'explanation': \"Despite acknowledging the product as 'quite good', the reviewer indicated the sweetness was excessive ('too sweet'), leading to an overall negative sentiment.\"}]]\n"
     ]
    }
   ],
   "source": [
    "response_schema = {\n",
    "    \"type\": \"ARRAY\",\n",
    "    \"items\": {\n",
    "        \"type\": \"ARRAY\",\n",
    "        \"items\": {\n",
    "            \"type\": \"OBJECT\",\n",
    "            \"properties\": {\n",
    "                \"rating\": {\"type\": \"INTEGER\"},\n",
    "                \"flavor\": {\"type\": \"STRING\"},\n",
    "                \"sentiment\": {\n",
    "                    \"type\": \"STRING\",\n",
    "                    \"enum\": [\"POSITIVE\", \"NEGATIVE\", \"NEUTRAL\"],\n",
    "                },\n",
    "                \"explanation\": {\"type\": \"STRING\"},\n",
    "            },\n",
    "            \"required\": [\"rating\", \"flavor\", \"sentiment\", \"explanation\"],\n",
    "        },\n",
    "    },\n",
    "}\n",
    "\n",
    "prompt = \"\"\"\n",
    "  Analyze the following product reviews, output the sentiment classification, and give an explanation.\n",
    "\n",
    "  - \"Absolutely loved it! Best ice cream I've ever had.\" Rating: 4, Flavor: Strawberry Cheesecake\n",
    "  - \"Quite good, but a bit too sweet for my taste.\" Rating: 1, Flavor: Mango Tango\n",
    "\"\"\"\n",
    "\n",
    "response = client.models.generate_content(\n",
    "    model=MODEL_ID,\n",
    "    contents=prompt,\n",
    "    config=GenerateContentConfig(\n",
    "        response_mime_type=\"application/json\",\n",
    "        response_schema=response_schema,\n",
    "    ),\n",
    ")\n",
    "\n",
    "response_dict = response.parsed\n",
    "print(response_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gV1dR-QlTKRs"
   },
   "source": [
    "## Count tokens and compute tokens\n",
    "\n",
    "You can use the `count_tokens()` method to calculate the number of input tokens before sending a request to the Gemini API.\n",
    "\n",
    "For more information, refer to [list and count tokens](https://cloud.google.com/vertex-ai/generative-ai/docs/multimodal/list-token)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Syx-fwLkV1j-"
   },
   "source": [
    "### Count tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "UhNElguLRRNK",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total_tokens=9 cached_content_token_count=None\n"
     ]
    }
   ],
   "source": [
    "response = client.models.count_tokens(\n",
    "    model=MODEL_ID,\n",
    "    contents=\"What's the highest mountain in Africa?\",\n",
    ")\n",
    "\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VS-AP7AHUQmV"
   },
   "source": [
    "### Compute tokens\n",
    "\n",
    "The `compute_tokens()` method runs a local tokenizer instead of making an API call. It also provides more detailed token information such as the `token_ids` and the `tokens` themselves\n",
    "\n",
    "<div class=\"alert alert-block alert-info\">\n",
    "<b>NOTE: This method is only supported in Vertex AI.</b>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "Cdhi5AX1TuH0",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tokens_info=[TokensInfo(role='user', token_ids=[1841, 235303, 235256, 573, 32514, 2204, 575, 573, 4645, 5255, 235336], tokens=[b'What', b\"'\", b's', b' the', b' longest', b' word', b' in', b' the', b' English', b' language', b'?'])]\n"
     ]
    }
   ],
   "source": [
    "response = client.models.compute_tokens(\n",
    "    model=MODEL_ID,\n",
    "    contents=\"What's the longest word in the English language?\",\n",
    ")\n",
    "\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_BsP0vXOY7hg"
   },
   "source": [
    "## Search as a tool (Grounding)\n",
    "\n",
    "[Grounding](https://cloud.google.com/vertex-ai/generative-ai/docs/multimodal/ground-gemini) lets you connect real-world data to the Gemini model.\n",
    "\n",
    "By grounding model responses in Google Search results, the model can access information at runtime that goes beyond its training data which can produce more accurate, up-to-date, and relevant responses.\n",
    "\n",
    "Using Grounding with Google Search, you can improve the accuracy and recency of responses from the model. Starting with Gemini 2.0, Google Search is available as a tool. This means that the model can decide when to use Google Search.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4_M_4RRBdO_3"
   },
   "source": [
    "### Google Search\n",
    "\n",
    "You can add the `tools` keyword argument with a `Tool` including `GoogleSearch` to instruct Gemini to first perform a Google Search with the prompt, then construct an answer based on the web search results.\n",
    "\n",
    "[Dynamic Retrieval](https://cloud.google.com/vertex-ai/generative-ai/docs/multimodal/ground-gemini#dynamic-retrieval) lets you set a threshold for when grounding is used for model responses. This is useful when the prompt doesn't require an answer grounded in Google Search and the supported models can provide an answer based on their knowledge without grounding. This helps you manage latency, quality, and cost more effectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "yeR09J3AZT4U",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "The next total solar eclipse in the contiguous United States will be on August 23, 2044. However, the path of totality will only touch three states: Montana, North Dakota, and South Dakota.\n",
       "\n",
       "Before that, a total solar eclipse will occur on March 30, 2033, but it will only be visible in Alaska.\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "grounding_chunks=[GroundingChunk(retrieved_context=None, web=GroundingChunkWeb(title='cbsnews.com', uri='https://vertexaisearch.cloud.google.com/grounding-api-redirect/AQXblrz4Ccq3Ruy45649oyGqmIAKl2FpQ76A4DA7vo049hIlhTlhgi9KRxiHU7tY9954YajMknTjBJQmN8H0hqOHzExVGpRxa_q2Qi-1dso9ohuJnSKv2uKnzHKC0QF59elTtKMN4jqjIXd6W9aND4cp0q4jiuKQZI5mubcb4A==')), GroundingChunk(retrieved_context=None, web=GroundingChunkWeb(title='nasa.gov', uri='https://vertexaisearch.cloud.google.com/grounding-api-redirect/AQXblrzEs1Zr26duiZmE3lFHLCfLUE69XJGveqXeo26FLGoa9Eu6qD_K5-AgkN2vr_oYenQl2xF0AK-vkMpEHGGi5yCjY0gniz0Fi5loiPSo284MrxOGijFQNfNDkLnVRBE0JLbADDVYdbCvSd8eTJMAYHnF7VWGuAx_f641')), GroundingChunk(retrieved_context=None, web=GroundingChunkWeb(title='wikipedia.org', uri='https://vertexaisearch.cloud.google.com/grounding-api-redirect/AQXblrwrj9uyQX5SS9aadYjIdaKKlatsdU3xvEU5dHYveWFhB2fvmAdJ7nd5ao9gvavHV-FLZ_aCgQKCUWnb5svG-P5M20s19bpufplx1EFS1ahzRpcr4hOUQzAVWxNPubg8VwhUpp_atJ1DzX6enLGCOmYiz8m0AfwS1GGC-zRBtar08yKqo60PUoARucQ7Huw='))] grounding_supports=[GroundingSupport(confidence_scores=[0.7496446, 0.9779277, 0.6572648], grounding_chunk_indices=[0, 1, 2], segment=Segment(end_index=88, part_index=None, start_index=None, text='The next total solar eclipse in the contiguous United States will be on August 23, 2044.')), GroundingSupport(confidence_scores=[0.74059933, 0.64566016], grounding_chunk_indices=[0, 2], segment=Segment(end_index=189, part_index=None, start_index=89, text='However, the path of totality will only touch three states: Montana, North Dakota, and South Dakota.')), GroundingSupport(confidence_scores=[0.80538523], grounding_chunk_indices=[2], segment=Segment(end_index=294, part_index=None, start_index=191, text='Before that, a total solar eclipse will occur on March 30, 2033, but it will only be visible in Alaska.'))] retrieval_metadata=RetrievalMetadata(google_search_dynamic_retrieval_score=None) retrieval_queries=None search_entry_point=SearchEntryPoint(rendered_content='<style>\\n.container {\\n  align-items: center;\\n  border-radius: 8px;\\n  display: flex;\\n  font-family: Google Sans, Roboto, sans-serif;\\n  font-size: 14px;\\n  line-height: 20px;\\n  padding: 8px 12px;\\n}\\n.chip {\\n  display: inline-block;\\n  border: solid 1px;\\n  border-radius: 16px;\\n  min-width: 14px;\\n  padding: 5px 16px;\\n  text-align: center;\\n  user-select: none;\\n  margin: 0 8px;\\n  -webkit-tap-highlight-color: transparent;\\n}\\n.carousel {\\n  overflow: auto;\\n  scrollbar-width: none;\\n  white-space: nowrap;\\n  margin-right: -12px;\\n}\\n.headline {\\n  display: flex;\\n  margin-right: 4px;\\n}\\n.gradient-container {\\n  position: relative;\\n}\\n.gradient {\\n  position: absolute;\\n  transform: translate(3px, -9px);\\n  height: 36px;\\n  width: 9px;\\n}\\n@media (prefers-color-scheme: light) {\\n  .container {\\n    background-color: #fafafa;\\n    box-shadow: 0 0 0 1px #0000000f;\\n  }\\n  .headline-label {\\n    color: #1f1f1f;\\n  }\\n  .chip {\\n    background-color: #ffffff;\\n    border-color: #d2d2d2;\\n    color: #5e5e5e;\\n    text-decoration: none;\\n  }\\n  .chip:hover {\\n    background-color: #f2f2f2;\\n  }\\n  .chip:focus {\\n    background-color: #f2f2f2;\\n  }\\n  .chip:active {\\n    background-color: #d8d8d8;\\n    border-color: #b6b6b6;\\n  }\\n  .logo-dark {\\n    display: none;\\n  }\\n  .gradient {\\n    background: linear-gradient(90deg, #fafafa 15%, #fafafa00 100%);\\n  }\\n}\\n@media (prefers-color-scheme: dark) {\\n  .container {\\n    background-color: #1f1f1f;\\n    box-shadow: 0 0 0 1px #ffffff26;\\n  }\\n  .headline-label {\\n    color: #fff;\\n  }\\n  .chip {\\n    background-color: #2c2c2c;\\n    border-color: #3c4043;\\n    color: #fff;\\n    text-decoration: none;\\n  }\\n  .chip:hover {\\n    background-color: #353536;\\n  }\\n  .chip:focus {\\n    background-color: #353536;\\n  }\\n  .chip:active {\\n    background-color: #464849;\\n    border-color: #53575b;\\n  }\\n  .logo-light {\\n    display: none;\\n  }\\n  .gradient {\\n    background: linear-gradient(90deg, #1f1f1f 15%, #1f1f1f00 100%);\\n  }\\n}\\n</style>\\n<div class=\"container\">\\n  <div class=\"headline\">\\n    <svg class=\"logo-light\" width=\"18\" height=\"18\" viewBox=\"9 9 35 35\" fill=\"none\" xmlns=\"http://www.w3.org/2000/svg\">\\n      <path fill-rule=\"evenodd\" clip-rule=\"evenodd\" d=\"M42.8622 27.0064C42.8622 25.7839 42.7525 24.6084 42.5487 23.4799H26.3109V30.1568H35.5897C35.1821 32.3041 33.9596 34.1222 32.1258 35.3448V39.6864H37.7213C40.9814 36.677 42.8622 32.2571 42.8622 27.0064V27.0064Z\" fill=\"#4285F4\"/>\\n      <path fill-rule=\"evenodd\" clip-rule=\"evenodd\" d=\"M26.3109 43.8555C30.9659 43.8555 34.8687 42.3195 37.7213 39.6863L32.1258 35.3447C30.5898 36.3792 28.6306 37.0061 26.3109 37.0061C21.8282 37.0061 18.0195 33.9811 16.6559 29.906H10.9194V34.3573C13.7563 39.9841 19.5712 43.8555 26.3109 43.8555V43.8555Z\" fill=\"#34A853\"/>\\n      <path fill-rule=\"evenodd\" clip-rule=\"evenodd\" d=\"M16.6559 29.8904C16.3111 28.8559 16.1074 27.7588 16.1074 26.6146C16.1074 25.4704 16.3111 24.3733 16.6559 23.3388V18.8875H10.9194C9.74388 21.2072 9.06992 23.8247 9.06992 26.6146C9.06992 29.4045 9.74388 32.022 10.9194 34.3417L15.3864 30.8621L16.6559 29.8904V29.8904Z\" fill=\"#FBBC05\"/>\\n      <path fill-rule=\"evenodd\" clip-rule=\"evenodd\" d=\"M26.3109 16.2386C28.85 16.2386 31.107 17.1164 32.9095 18.8091L37.8466 13.8719C34.853 11.082 30.9659 9.3736 26.3109 9.3736C19.5712 9.3736 13.7563 13.245 10.9194 18.8875L16.6559 23.3388C18.0195 19.2636 21.8282 16.2386 26.3109 16.2386V16.2386Z\" fill=\"#EA4335\"/>\\n    </svg>\\n    <svg class=\"logo-dark\" width=\"18\" height=\"18\" viewBox=\"0 0 48 48\" xmlns=\"http://www.w3.org/2000/svg\">\\n      <circle cx=\"24\" cy=\"23\" fill=\"#FFF\" r=\"22\"/>\\n      <path d=\"M33.76 34.26c2.75-2.56 4.49-6.37 4.49-11.26 0-.89-.08-1.84-.29-3H24.01v5.99h8.03c-.4 2.02-1.5 3.56-3.07 4.56v.75l3.91 2.97h.88z\" fill=\"#4285F4\"/>\\n      <path d=\"M15.58 25.77A8.845 8.845 0 0 0 24 31.86c1.92 0 3.62-.46 4.97-1.31l4.79 3.71C31.14 36.7 27.65 38 24 38c-5.93 0-11.01-3.4-13.45-8.36l.17-1.01 4.06-2.85h.8z\" fill=\"#34A853\"/>\\n      <path d=\"M15.59 20.21a8.864 8.864 0 0 0 0 5.58l-5.03 3.86c-.98-2-1.53-4.25-1.53-6.64 0-2.39.55-4.64 1.53-6.64l1-.22 3.81 2.98.22 1.08z\" fill=\"#FBBC05\"/>\\n      <path d=\"M24 14.14c2.11 0 4.02.75 5.52 1.98l4.36-4.36C31.22 9.43 27.81 8 24 8c-5.93 0-11.01 3.4-13.45 8.36l5.03 3.85A8.86 8.86 0 0 1 24 14.14z\" fill=\"#EA4335\"/>\\n    </svg>\\n    <div class=\"gradient-container\"><div class=\"gradient\"></div></div>\\n  </div>\\n  <div class=\"carousel\">\\n    <a class=\"chip\" href=\"https://vertexaisearch.cloud.google.com/grounding-api-redirect/AQXblrxUK3rjuj2ov51XWBsoxBu1Ylk3CQypC7TZ5YjgWxzWTC1mdAGdkdGAxQZu_BX5LnZX6qnEeB45G_Gfwzr4Auw8OcjORO0ZPX-Y_NJAPnT2bmkin0-iawcuPB13so3bKscT8EbDa_Mq2KrHSrxIGBrhFl_Eim6uALP5gpEYlL4BRRjMW5O4Rjanji5LcfxmEr0XM-z9ydV_3QI0F13jTA==\">next total solar eclipse USA</a>\\n  </div>\\n</div>\\n', sdk_blob=None) web_search_queries=['next total solar eclipse USA']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       ".container {\n",
       "  align-items: center;\n",
       "  border-radius: 8px;\n",
       "  display: flex;\n",
       "  font-family: Google Sans, Roboto, sans-serif;\n",
       "  font-size: 14px;\n",
       "  line-height: 20px;\n",
       "  padding: 8px 12px;\n",
       "}\n",
       ".chip {\n",
       "  display: inline-block;\n",
       "  border: solid 1px;\n",
       "  border-radius: 16px;\n",
       "  min-width: 14px;\n",
       "  padding: 5px 16px;\n",
       "  text-align: center;\n",
       "  user-select: none;\n",
       "  margin: 0 8px;\n",
       "  -webkit-tap-highlight-color: transparent;\n",
       "}\n",
       ".carousel {\n",
       "  overflow: auto;\n",
       "  scrollbar-width: none;\n",
       "  white-space: nowrap;\n",
       "  margin-right: -12px;\n",
       "}\n",
       ".headline {\n",
       "  display: flex;\n",
       "  margin-right: 4px;\n",
       "}\n",
       ".gradient-container {\n",
       "  position: relative;\n",
       "}\n",
       ".gradient {\n",
       "  position: absolute;\n",
       "  transform: translate(3px, -9px);\n",
       "  height: 36px;\n",
       "  width: 9px;\n",
       "}\n",
       "@media (prefers-color-scheme: light) {\n",
       "  .container {\n",
       "    background-color: #fafafa;\n",
       "    box-shadow: 0 0 0 1px #0000000f;\n",
       "  }\n",
       "  .headline-label {\n",
       "    color: #1f1f1f;\n",
       "  }\n",
       "  .chip {\n",
       "    background-color: #ffffff;\n",
       "    border-color: #d2d2d2;\n",
       "    color: #5e5e5e;\n",
       "    text-decoration: none;\n",
       "  }\n",
       "  .chip:hover {\n",
       "    background-color: #f2f2f2;\n",
       "  }\n",
       "  .chip:focus {\n",
       "    background-color: #f2f2f2;\n",
       "  }\n",
       "  .chip:active {\n",
       "    background-color: #d8d8d8;\n",
       "    border-color: #b6b6b6;\n",
       "  }\n",
       "  .logo-dark {\n",
       "    display: none;\n",
       "  }\n",
       "  .gradient {\n",
       "    background: linear-gradient(90deg, #fafafa 15%, #fafafa00 100%);\n",
       "  }\n",
       "}\n",
       "@media (prefers-color-scheme: dark) {\n",
       "  .container {\n",
       "    background-color: #1f1f1f;\n",
       "    box-shadow: 0 0 0 1px #ffffff26;\n",
       "  }\n",
       "  .headline-label {\n",
       "    color: #fff;\n",
       "  }\n",
       "  .chip {\n",
       "    background-color: #2c2c2c;\n",
       "    border-color: #3c4043;\n",
       "    color: #fff;\n",
       "    text-decoration: none;\n",
       "  }\n",
       "  .chip:hover {\n",
       "    background-color: #353536;\n",
       "  }\n",
       "  .chip:focus {\n",
       "    background-color: #353536;\n",
       "  }\n",
       "  .chip:active {\n",
       "    background-color: #464849;\n",
       "    border-color: #53575b;\n",
       "  }\n",
       "  .logo-light {\n",
       "    display: none;\n",
       "  }\n",
       "  .gradient {\n",
       "    background: linear-gradient(90deg, #1f1f1f 15%, #1f1f1f00 100%);\n",
       "  }\n",
       "}\n",
       "</style>\n",
       "<div class=\"container\">\n",
       "  <div class=\"headline\">\n",
       "    <svg class=\"logo-light\" width=\"18\" height=\"18\" viewBox=\"9 9 35 35\" fill=\"none\" xmlns=\"http://www.w3.org/2000/svg\">\n",
       "      <path fill-rule=\"evenodd\" clip-rule=\"evenodd\" d=\"M42.8622 27.0064C42.8622 25.7839 42.7525 24.6084 42.5487 23.4799H26.3109V30.1568H35.5897C35.1821 32.3041 33.9596 34.1222 32.1258 35.3448V39.6864H37.7213C40.9814 36.677 42.8622 32.2571 42.8622 27.0064V27.0064Z\" fill=\"#4285F4\"/>\n",
       "      <path fill-rule=\"evenodd\" clip-rule=\"evenodd\" d=\"M26.3109 43.8555C30.9659 43.8555 34.8687 42.3195 37.7213 39.6863L32.1258 35.3447C30.5898 36.3792 28.6306 37.0061 26.3109 37.0061C21.8282 37.0061 18.0195 33.9811 16.6559 29.906H10.9194V34.3573C13.7563 39.9841 19.5712 43.8555 26.3109 43.8555V43.8555Z\" fill=\"#34A853\"/>\n",
       "      <path fill-rule=\"evenodd\" clip-rule=\"evenodd\" d=\"M16.6559 29.8904C16.3111 28.8559 16.1074 27.7588 16.1074 26.6146C16.1074 25.4704 16.3111 24.3733 16.6559 23.3388V18.8875H10.9194C9.74388 21.2072 9.06992 23.8247 9.06992 26.6146C9.06992 29.4045 9.74388 32.022 10.9194 34.3417L15.3864 30.8621L16.6559 29.8904V29.8904Z\" fill=\"#FBBC05\"/>\n",
       "      <path fill-rule=\"evenodd\" clip-rule=\"evenodd\" d=\"M26.3109 16.2386C28.85 16.2386 31.107 17.1164 32.9095 18.8091L37.8466 13.8719C34.853 11.082 30.9659 9.3736 26.3109 9.3736C19.5712 9.3736 13.7563 13.245 10.9194 18.8875L16.6559 23.3388C18.0195 19.2636 21.8282 16.2386 26.3109 16.2386V16.2386Z\" fill=\"#EA4335\"/>\n",
       "    </svg>\n",
       "    <svg class=\"logo-dark\" width=\"18\" height=\"18\" viewBox=\"0 0 48 48\" xmlns=\"http://www.w3.org/2000/svg\">\n",
       "      <circle cx=\"24\" cy=\"23\" fill=\"#FFF\" r=\"22\"/>\n",
       "      <path d=\"M33.76 34.26c2.75-2.56 4.49-6.37 4.49-11.26 0-.89-.08-1.84-.29-3H24.01v5.99h8.03c-.4 2.02-1.5 3.56-3.07 4.56v.75l3.91 2.97h.88z\" fill=\"#4285F4\"/>\n",
       "      <path d=\"M15.58 25.77A8.845 8.845 0 0 0 24 31.86c1.92 0 3.62-.46 4.97-1.31l4.79 3.71C31.14 36.7 27.65 38 24 38c-5.93 0-11.01-3.4-13.45-8.36l.17-1.01 4.06-2.85h.8z\" fill=\"#34A853\"/>\n",
       "      <path d=\"M15.59 20.21a8.864 8.864 0 0 0 0 5.58l-5.03 3.86c-.98-2-1.53-4.25-1.53-6.64 0-2.39.55-4.64 1.53-6.64l1-.22 3.81 2.98.22 1.08z\" fill=\"#FBBC05\"/>\n",
       "      <path d=\"M24 14.14c2.11 0 4.02.75 5.52 1.98l4.36-4.36C31.22 9.43 27.81 8 24 8c-5.93 0-11.01 3.4-13.45 8.36l5.03 3.85A8.86 8.86 0 0 1 24 14.14z\" fill=\"#EA4335\"/>\n",
       "    </svg>\n",
       "    <div class=\"gradient-container\"><div class=\"gradient\"></div></div>\n",
       "  </div>\n",
       "  <div class=\"carousel\">\n",
       "    <a class=\"chip\" href=\"https://vertexaisearch.cloud.google.com/grounding-api-redirect/AQXblrxUK3rjuj2ov51XWBsoxBu1Ylk3CQypC7TZ5YjgWxzWTC1mdAGdkdGAxQZu_BX5LnZX6qnEeB45G_Gfwzr4Auw8OcjORO0ZPX-Y_NJAPnT2bmkin0-iawcuPB13so3bKscT8EbDa_Mq2KrHSrxIGBrhFl_Eim6uALP5gpEYlL4BRRjMW5O4Rjanji5LcfxmEr0XM-z9ydV_3QI0F13jTA==\">next total solar eclipse USA</a>\n",
       "  </div>\n",
       "</div>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "google_search_tool = Tool(google_search=GoogleSearch())\n",
    "\n",
    "response = client.models.generate_content(\n",
    "    model=MODEL_ID,\n",
    "    contents=\"When is the next total solar eclipse in the United States?\",\n",
    "    config=GenerateContentConfig(tools=[google_search_tool]),\n",
    ")\n",
    "\n",
    "display(Markdown(response.text))\n",
    "\n",
    "print(response.candidates[0].grounding_metadata)\n",
    "\n",
    "HTML(response.candidates[0].grounding_metadata.search_entry_point.rendered_content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<b>NOTE: For the purposes of this lab, you will skip the following Vertex AI Search section as you do not have a data store to ground your model.</b>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hYKAzG1sH-K1"
   },
   "source": [
    "### Vertex AI Search\n",
    "\n",
    "You can use a [Vertex AI Search data store](https://cloud.google.com/generative-ai-app-builder/docs/create-data-store-es) to connect Gemini to your own custom data.\n",
    "\n",
    "Follow the [get started guide for Vertex AI Search](https://cloud.google.com/generative-ai-app-builder/docs/try-enterprise-search) for more information."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "T0pb-Kh1xEHU"
   },
   "source": [
    "## Function calling\n",
    "\n",
    "[Function Calling](https://cloud.google.com/vertex-ai/docs/generative-ai/multimodal/function-calling) in Gemini lets developers create a description of a function in their code, then pass that description to a language model in a request.\n",
    "\n",
    "You can submit a Python function for automatic function calling, which will run the function and return the output in natural language generated by Gemini.\n",
    "\n",
    "You can also submit an [OpenAPI Specification](https://www.openapis.org/) which will respond with the name of a function that matches the description and the arguments to call it with."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mSUWWlrrlR-D"
   },
   "source": [
    "### Python Function (Automatic Function Calling)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "aRR8HZhLlR-E",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "It's hot in Austin.\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def get_current_weather(location: str) -> str:\n",
    "    \"\"\"Example method. Returns the current weather.\n",
    "\n",
    "    Args:\n",
    "        location: The city and state, e.g. San Francisco, CA\n",
    "    \"\"\"\n",
    "    weather_map: dict[str, str] = {\n",
    "        \"Boston, MA\": \"snowing\",\n",
    "        \"San Francisco, CA\": \"foggy\",\n",
    "        \"Seattle, WA\": \"raining\",\n",
    "        \"Austin, TX\": \"hot\",\n",
    "        \"Chicago, IL\": \"windy\",\n",
    "    }\n",
    "    return weather_map.get(location, \"unknown\")\n",
    "\n",
    "\n",
    "response = client.models.generate_content(\n",
    "    model=MODEL_ID,\n",
    "    contents=\"What is the weather like in Austin?\",\n",
    "    config=GenerateContentConfig(\n",
    "        tools=[get_current_weather],\n",
    "        temperature=0,\n",
    "    ),\n",
    ")\n",
    "\n",
    "display(Markdown(response.text))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "h4syyLEClGcn"
   },
   "source": [
    "### OpenAPI Specification (Manual Function Calling)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "2BDQPwgcxRN3",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id=None args={'destination': 'Paris'} name='get_destination'\n"
     ]
    }
   ],
   "source": [
    "get_destination = FunctionDeclaration(\n",
    "    name=\"get_destination\",\n",
    "    description=\"Get the destination that the user wants to go to\",\n",
    "    parameters={\n",
    "        \"type\": \"OBJECT\",\n",
    "        \"properties\": {\n",
    "            \"destination\": {\n",
    "                \"type\": \"STRING\",\n",
    "                \"description\": \"Destination that the user wants to go to\",\n",
    "            },\n",
    "        },\n",
    "    },\n",
    ")\n",
    "\n",
    "destination_tool = Tool(\n",
    "    function_declarations=[get_destination],\n",
    ")\n",
    "\n",
    "response = client.models.generate_content(\n",
    "    model=MODEL_ID,\n",
    "    contents=\"I'd like to travel to Paris.\",\n",
    "    config=GenerateContentConfig(\n",
    "        tools=[destination_tool],\n",
    "        temperature=0,\n",
    "    ),\n",
    ")\n",
    "\n",
    "print(response.function_calls[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MhDs2X3o0neK"
   },
   "source": [
    "## Code Execution\n",
    "\n",
    "The Gemini API [code execution](https://ai.google.dev/gemini-api/docs/code-execution?lang=python) feature enables the model to generate and run Python code and learn iteratively from the results until it arrives at a final output. You can use this code execution capability to build applications that benefit from code-based reasoning and that produce text output. For example, you could use code execution in an application that solves equations or processes text.\n",
    "\n",
    "The Gemini API provides code execution as a tool, similar to function calling.\n",
    "After you add code execution as a tool, the model decides when to use it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1W-3c7sy0nyz"
   },
   "outputs": [],
   "source": [
    "code_execution_tool = Tool(code_execution=ToolCodeExecution())\n",
    "\n",
    "response = client.models.generate_content(\n",
    "    model=MODEL_ID,\n",
    "    contents=\"Calculate 20th fibonacci number. Then find the nearest palindrome to it.\",\n",
    "    config=GenerateContentConfig(\n",
    "        tools=[code_execution_tool],\n",
    "        temperature=0,\n",
    "    ),\n",
    ")\n",
    "for part in response.candidates[0].content.parts:\n",
    "    if part.executable_code:\n",
    "        print(\"Language:\", part.executable_code.language)\n",
    "        display(\n",
    "            Markdown(\n",
    "                f\"\"\"\n",
    "```\n",
    "{part.executable_code.code}\n",
    "```\n",
    "\"\"\"\n",
    "            )\n",
    "        )\n",
    "    if part.code_execution_result:\n",
    "        print(\"\\nOutcome:\", part.code_execution_result.outcome)\n",
    "        display(Markdown(f\"`{part.code_execution_result.output}`\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9d2d8fdf1d12"
   },
   "source": [
    "## Spatial Understanding\n",
    "\n",
    "Gemini 2.0 includes improved spatial understanding and object detection capabilities. Check out this notebook for examples:\n",
    "\n",
    "- [2D spatial understanding with Gemini 2.0](https://github.com/GoogleCloudPlatform/generative-ai/blob/main/gemini/use-cases/spatial-understanding/spatial_understanding.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eQwiONFdVHw5"
   },
   "source": [
    "## What's next\n",
    "\n",
    "- See the [Google Gen AI SDK reference docs](https://googleapis.github.io/python-genai/).\n",
    "- Explore other notebooks in the [Google Cloud Generative AI GitHub repository](https://github.com/GoogleCloudPlatform/generative-ai).\n",
    "- Explore AI models in [Model Garden](https://cloud.google.com/vertex-ai/generative-ai/docs/model-garden/explore-models)."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "intro_gemini_2_0_flash.ipynb",
   "toc_visible": true
  },
  "environment": {
   "kernel": "conda-base-py",
   "name": "workbench-notebooks.m128",
   "type": "gcloud",
   "uri": "us-docker.pkg.dev/deeplearning-platform-release/gcr.io/workbench-notebooks:m128"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel) (Local) (Local)",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
